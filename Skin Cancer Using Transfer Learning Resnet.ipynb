{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d81e64c6",
   "metadata": {},
   "source": [
    "# Requirements\n",
    "\n",
    "## Data Format\n",
    "\n",
    "Images are also provided in **`JPEG`** resized a uniform **`512x512`**.\n",
    "\n",
    "Metadata is also provided outside of the DICOM format, in CSV files. See the Columns section for a description.\n",
    "\n",
    "## What to predict. \n",
    "We have to predict a binary target for each image. The model model should predict the probability (floating point) between 0.0 and 1.0 that the lesion in the image is malignant (the target). In the training data, `train.csv`, the **value 0 denotes benign, and 1 indicates malignant.**\n",
    "\n",
    "## Data Set Files\n",
    "The dataset consists of images in :\n",
    "* JPEG format in JPEG directory\n",
    "\n",
    "Additionally, there is a metadata comprising of train, test and submission file in CSV format.\n",
    "So the whole dataset looks like the following\n",
    "* **train_color(dir)**\n",
    "    * train_color --> all the jpg images in training  set\n",
    "* **test_color(dir)**\n",
    "    * test_color --> all the jpg images in testset    \n",
    "* **train.csv** --> the training set metadata\n",
    "* **test.csv**  -->the test set metadata\n",
    "* sample_submission.csv --> a sample submission file in the correct format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1883a9e9",
   "metadata": {},
   "source": [
    "# 1. Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72a60fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-28 19:12:07.850443: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-28 19:12:07.947677: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-04-28 19:12:07.947695: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-04-28 19:12:07.970997: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-04-28 19:12:08.553332: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-04-28 19:12:08.553401: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-04-28 19:12:08.553409: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import os\n",
    "from pathlib import Path\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from datetime import datetime, date\n",
    "\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D,GlobalAveragePooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbe1880d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1\n",
    "EPOCHS = 300\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 2\n",
    "VERBOSE_LEVEL = 1\n",
    "SAVE_OUTPUT = True\n",
    "IMG_SIZE = (224, 224)\n",
    "INPUT_SHAPE = (224, 224, 3)\n",
    "\n",
    "CWD = os.getcwd()\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4a5a98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = './'\n",
    "PATH_TO_IMAGES = './train_color/train_color/' \n",
    "IMAGE_TYPE = \".jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7b60655",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Helper function to validate the image paths\n",
    "\n",
    "    Parameters:\n",
    "        file_path (string): Path to the image \n",
    "\n",
    "    Returns:\n",
    "        The file path if the file exists, otherwise false if the file does not exist\n",
    "\n",
    "\"\"\"\n",
    "def check_image(file_path):\n",
    "    img_file = Path(file_path)\n",
    "    if img_file.is_file():\n",
    "        return file_path\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbc467c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Helper function to get the train dataset\n",
    "\"\"\"\n",
    "def get_train_data():\n",
    "    # read the data from the train.csv file\n",
    "    train = pd.read_csv(os.path.join(BASE_PATH, 'train.csv'))\n",
    "    # add the image_path to the train set\n",
    "    train['image_path'] = train['image_name'].apply(lambda x: PATH_TO_IMAGES + x + IMAGE_TYPE)\n",
    "    # check if the we have an image \n",
    "    train['image_path'] = train.apply(lambda row : check_image(row['image_path']), axis = 1)\n",
    "    # if we do not have an image we will not include the data\n",
    "    train = train[train['image_path'] != False]\n",
    "    print(\"valid rows in train\", train.shape[0])\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4107b3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid rows in train 33126\n"
     ]
    }
   ],
   "source": [
    "train_df = get_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6af2196f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>sex</th>\n",
       "      <th>age_approx</th>\n",
       "      <th>anatom_site_general_challenge</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>benign_malignant</th>\n",
       "      <th>target</th>\n",
       "      <th>tfrecord</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_2637011</td>\n",
       "      <td>IP_7279968</td>\n",
       "      <td>male</td>\n",
       "      <td>45.0</td>\n",
       "      <td>head/neck</td>\n",
       "      <td>unknown</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6000</td>\n",
       "      <td>4000</td>\n",
       "      <td>./train_color/train_color/ISIC_2637011.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0015719</td>\n",
       "      <td>IP_3075186</td>\n",
       "      <td>female</td>\n",
       "      <td>45.0</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>unknown</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6000</td>\n",
       "      <td>4000</td>\n",
       "      <td>./train_color/train_color/ISIC_0015719.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0052212</td>\n",
       "      <td>IP_2842074</td>\n",
       "      <td>female</td>\n",
       "      <td>50.0</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>nevus</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1872</td>\n",
       "      <td>1053</td>\n",
       "      <td>./train_color/train_color/ISIC_0052212.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_0068279</td>\n",
       "      <td>IP_6890425</td>\n",
       "      <td>female</td>\n",
       "      <td>45.0</td>\n",
       "      <td>head/neck</td>\n",
       "      <td>unknown</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1872</td>\n",
       "      <td>1053</td>\n",
       "      <td>./train_color/train_color/ISIC_0068279.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_0074268</td>\n",
       "      <td>IP_8723313</td>\n",
       "      <td>female</td>\n",
       "      <td>55.0</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>unknown</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>6000</td>\n",
       "      <td>4000</td>\n",
       "      <td>./train_color/train_color/ISIC_0074268.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     image_name  patient_id     sex  age_approx anatom_site_general_challenge  \\\n",
       "0  ISIC_2637011  IP_7279968    male        45.0                     head/neck   \n",
       "1  ISIC_0015719  IP_3075186  female        45.0               upper extremity   \n",
       "2  ISIC_0052212  IP_2842074  female        50.0               lower extremity   \n",
       "3  ISIC_0068279  IP_6890425  female        45.0                     head/neck   \n",
       "4  ISIC_0074268  IP_8723313  female        55.0               upper extremity   \n",
       "\n",
       "  diagnosis benign_malignant  target  tfrecord  width  height  \\\n",
       "0   unknown           benign       0         0   6000    4000   \n",
       "1   unknown           benign       0         0   6000    4000   \n",
       "2     nevus           benign       0         6   1872    1053   \n",
       "3   unknown           benign       0         0   1872    1053   \n",
       "4   unknown           benign       0        11   6000    4000   \n",
       "\n",
       "                                   image_path  \n",
       "0  ./train_color/train_color/ISIC_2637011.jpg  \n",
       "1  ./train_color/train_color/ISIC_0015719.jpg  \n",
       "2  ./train_color/train_color/ISIC_0052212.jpg  \n",
       "3  ./train_color/train_color/ISIC_0068279.jpg  \n",
       "4  ./train_color/train_color/ISIC_0074268.jpg  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5fcb42",
   "metadata": {},
   "source": [
    "# Metadata Description\n",
    "### Columns of `train.csv`\n",
    "* image_name - unique identifier, points to filename of related DICOM image\n",
    "* patient_id - unique patient identifier\n",
    "* sex - the sex of the patient (when unknown, will be blank)\n",
    "* age_approx - approximate patient age at time of imaging\n",
    "* anatom_site_general_challenge - location of imaged site\n",
    "* diagnosis - detailed diagnosis information (train only)\n",
    "* benign_malignant - indicator of malignancy of imaged lesion\n",
    "* target - binarized version of the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77386f46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>columns</th>\n",
       "      <th>percent_null</th>\n",
       "      <th>percent_zero</th>\n",
       "      <th>total_zero</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>image_name</th>\n",
       "      <td>image_name</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient_id</th>\n",
       "      <td>patient_id</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>sex</td>\n",
       "      <td>0.196220</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.196220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_approx</th>\n",
       "      <td>age_approx</td>\n",
       "      <td>0.205277</td>\n",
       "      <td>0.006038</td>\n",
       "      <td>0.211314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anatom_site_general_challenge</th>\n",
       "      <td>anatom_site_general_challenge</td>\n",
       "      <td>1.590895</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.590895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diagnosis</th>\n",
       "      <td>diagnosis</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>benign_malignant</th>\n",
       "      <td>benign_malignant</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>target</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98.237034</td>\n",
       "      <td>98.237034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfrecord</th>\n",
       "      <td>tfrecord</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.586971</td>\n",
       "      <td>6.586971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>width</th>\n",
       "      <td>width</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>height</th>\n",
       "      <td>height</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image_path</th>\n",
       "      <td>image_path</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     columns  percent_null  \\\n",
       "image_name                                        image_name      0.000000   \n",
       "patient_id                                        patient_id      0.000000   \n",
       "sex                                                      sex      0.196220   \n",
       "age_approx                                        age_approx      0.205277   \n",
       "anatom_site_general_challenge  anatom_site_general_challenge      1.590895   \n",
       "diagnosis                                          diagnosis      0.000000   \n",
       "benign_malignant                            benign_malignant      0.000000   \n",
       "target                                                target      0.000000   \n",
       "tfrecord                                            tfrecord      0.000000   \n",
       "width                                                  width      0.000000   \n",
       "height                                                height      0.000000   \n",
       "image_path                                        image_path      0.000000   \n",
       "\n",
       "                               percent_zero  total_zero  \n",
       "image_name                         0.000000    0.000000  \n",
       "patient_id                         0.000000    0.000000  \n",
       "sex                                0.000000    0.196220  \n",
       "age_approx                         0.006038    0.211314  \n",
       "anatom_site_general_challenge      0.000000    1.590895  \n",
       "diagnosis                          0.000000    0.000000  \n",
       "benign_malignant                   0.000000    0.000000  \n",
       "target                            98.237034   98.237034  \n",
       "tfrecord                           6.586971    6.586971  \n",
       "width                              0.000000    0.000000  \n",
       "height                             0.000000    0.000000  \n",
       "image_path                         0.000000    0.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Helper function check a dataframe for missing values\n",
    "    Parameters:\n",
    "\n",
    "        df (dataframe): The dataframe to check\n",
    "    Returns:\n",
    "        A dataframe with the number of missing and zero values for each column in percent\n",
    "\"\"\"\n",
    "def check_for_missing_and_null(df):\n",
    "    null_df = pd.DataFrame({'columns': df.columns, \n",
    "                            'percent_null': df.isnull().sum() * 100 / len(df), \n",
    "                            'percent_zero': df.isin([0]).sum() * 100 / len(df),\n",
    "                            'total_zero': df.isnull().sum() * 100 / len(df) + df.isin([0]).sum() * 100 / len(df),\n",
    "                           })\n",
    "    return null_df\n",
    "\n",
    "check_for_missing_and_null(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bdd2623",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b69895e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows in train 32531\n"
     ]
    }
   ],
   "source": [
    "# getting dummy variables for gender\n",
    "sex_dummies = pd.get_dummies(train['sex'], prefix='sex', dtype=\"int\")\n",
    "train = pd.concat([train, sex_dummies], axis=1)\n",
    "\n",
    "# getting dummy variables for anatom_site_general_challenge\n",
    "anatom_dummies = pd.get_dummies(train['anatom_site_general_challenge'], prefix='anatom', dtype=\"int\")\n",
    "train = pd.concat([train, anatom_dummies], axis=1)\n",
    "\n",
    "# getting dummy variables for target column\n",
    "#target_dummies = pd.get_dummies(train['target'], prefix='target', dtype=\"int\")\n",
    "#train = pd.concat([train, target_dummies], axis=1)\n",
    "\n",
    "# dropping not useful columns\n",
    "train.drop(['sex','diagnosis','benign_malignant','anatom_site_general_challenge'], axis=1, inplace=True)\n",
    "\n",
    "# replace missing age values wiht the mean age\n",
    "train['age_approx'] = train['age_approx'].fillna(int(np.mean(train['age_approx'])))\n",
    "\n",
    "# convert age to int\n",
    "train['age_approx'] = train['age_approx'].astype('int')\n",
    "\n",
    "print(\"rows in train\", train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd164448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples in train 0.5\n",
      "Remaining rows in train set 1150\n"
     ]
    }
   ],
   "source": [
    "# 1 means 50 / 50 => equal amount of positive and negative cases in Training\n",
    "# 4 = 20%; 8 = ~11%; 12 = ~8%\n",
    "balance = 1\n",
    "p_inds = train[train.target == 1].index.tolist()\n",
    "np_inds = train[train.target == 0].index.tolist()\n",
    "\n",
    "np_sample = random.sample(np_inds, balance * len(p_inds))\n",
    "train = train.loc[p_inds + np_sample]\n",
    "print(\"Samples in train\", train['target'].sum()/len(train))\n",
    "print(\"Remaining rows in train set\", len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02e32163",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Helper function to create a train and a validation dataset\n",
    "\n",
    "    Parameters:\n",
    "    df (dataframe): The dataframe to split\n",
    "    test_size (int): Size of the validation set\n",
    "    classToPredict: The target column\n",
    "\n",
    "    Returns:\n",
    "    train_data (dataframe)\n",
    "    val_data (dataframe)\n",
    "\"\"\"\n",
    "def create_splits(df, test_size, classToPredict):\n",
    "    train_data, val_data = train_test_split(df,  test_size = test_size, random_state = 1, stratify = df[classToPredict])\n",
    "    train_data, test_data = train_test_split(df,  test_size = 0.16, random_state = 1, stratify = df[classToPredict])\n",
    "    return train_data, val_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ddf8e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Helper function to plot the history of a tensorflow model\n",
    "\n",
    "    Parameters:\n",
    "        history (history object): The history from a tf model\n",
    "        timestamp (string): The timestamp of the function execution\n",
    "\n",
    "    Returns:\n",
    "        Null\n",
    "\"\"\"\n",
    "def save_history(history, timestamp):\n",
    "    f = plt.figure()\n",
    "    f.set_figwidth(15)\n",
    "\n",
    "    f.add_subplot(1, 2, 1)\n",
    "    plt.plot(history['val_loss'], label='val loss')\n",
    "    plt.plot(history['loss'], label='train loss')\n",
    "    plt.legend()\n",
    "    plt.title(\"Modell Loss\")\n",
    "\n",
    "    f.add_subplot(1, 2, 2)\n",
    "    plt.plot(history['val_accuracy'], label='val accuracy')\n",
    "    plt.plot(history['accuracy'], label='train accuracy')\n",
    "    plt.legend()\n",
    "    plt.title(\"Modell Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccccb99",
   "metadata": {},
   "source": [
    "## Transfer Learning with Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b272311",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.utils as image\n",
    "\n",
    "def extract_features(df):\n",
    "    features = []\n",
    "    labels = []\n",
    "    for img_path in df['image_path']:\n",
    "        img = image.load_img(img_path, target_size=INPUT_SHAPE)\n",
    "        img_data = image.img_to_array(img)\n",
    "        features.append(img_data)\n",
    "        labels.append(df.loc[df['image_path'] == img_path, 'target'].iloc[0])\n",
    "        \n",
    "    feature_list_np = np.array(features)\n",
    "    labels_list_np = np.array(labels)\n",
    "    \n",
    "    return feature_list_np, labels_list_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b01fb8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows in train_df 966\n",
      "rows in val_df 230\n",
      "rows in test_df 184\n"
     ]
    }
   ],
   "source": [
    "# create a training and validation dataset from the train df\n",
    "train_df, val_df, test_df = create_splits(train, 0.2, 'target')\n",
    "\n",
    "print(\"rows in train_df\", train_df.shape[0])\n",
    "print(\"rows in val_df\", val_df.shape[0])\n",
    "print(\"rows in test_df\", test_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1091160b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, train_labels = extract_features(train_df)\n",
    "val_features, val_labels = extract_features(val_df)\n",
    "test_features, test_labels = extract_features(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93706835",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train_features, train_labels\n",
    "X_val, y_val = val_features, val_labels\n",
    "X_test, y_test = test_features, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1eec9d63",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-28 19:13:58.702042: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-28 19:13:58.702287: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-04-28 19:13:58.702347: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2023-04-28 19:13:58.702404: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2023-04-28 19:13:58.702461: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2023-04-28 19:13:58.702518: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2023-04-28 19:13:58.702574: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2023-04-28 19:13:58.702630: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2023-04-28 19:13:58.702687: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-04-28 19:13:58.702696: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-04-28 19:13:58.702901: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "base_model = ResNet50(include_top=False, pooling='avg', weights='imagenet', input_shape=INPUT_SHAPE)\n",
    "for layer in base_model.layers[:-4]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "63f0c5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "STEPS_PER_EPOCH = 966 // 32\n",
    "VALID_STEPS = 230 // 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "75544774",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_name='melanoma_model.h5', force_train=False):\n",
    "    if not force_train and os.path.isfile(model_name):\n",
    "        print(\"Loading model from file:\", model_name)\n",
    "        my_model = tf.keras.models.load_model(model_name)\n",
    "        return my_model\n",
    "    \n",
    "    my_model = Sequential([base_model])\n",
    "    my_model.add(Dense(512, activation='relu'))\n",
    "    my_model.add(Dropout(0.5))\n",
    "    my_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    my_model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "                 loss='binary_crossentropy',\n",
    "                 metrics=['accuracy', tf.keras.metrics.Recall()])\n",
    "\n",
    "    checkpoint = ModelCheckpoint(model_name,\n",
    "                                monitor=\"val_loss\",\n",
    "                                mode=\"min\",\n",
    "                                save_best_only=True,\n",
    "                                verbose=1)\n",
    "\n",
    "    earlystopping = EarlyStopping(monitor='val_loss',min_delta=0, patience=5, verbose=1, restore_best_weights=True)\n",
    "\n",
    "    try:\n",
    "        history = my_model.fit(X_train,y_train,\n",
    "                               epochs=15,\n",
    "                               steps_per_epoch=STEPS_PER_EPOCH,\n",
    "                               validation_data=(X_val,y_val),\n",
    "                               validation_steps=VALID_STEPS,\n",
    "                               callbacks=[checkpoint, earlystopping]\n",
    "                              )\n",
    "        print(\"Model training completed successfully.\")\n",
    "        return my_model\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nTraining Stopped\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "85f9d739",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-28 19:16:23.771860: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 581640192 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - ETA: 0s - loss: 0.6779 - accuracy: 0.6356 - recall: 0.6667"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-28 19:17:32.535084: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 138485760 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 0.57203, saving model to melanoma_model.h5\n",
      "30/30 [==============================] - 94s 3s/step - loss: 0.6779 - accuracy: 0.6356 - recall: 0.6667 - val_loss: 0.5720 - val_accuracy: 0.7130 - val_recall: 0.7043\n",
      "Epoch 2/15\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.5417 - accuracy: 0.7277 - recall: 0.7557\n",
      "Epoch 2: val_loss improved from 0.57203 to 0.55216, saving model to melanoma_model.h5\n",
      "30/30 [==============================] - 78s 3s/step - loss: 0.5417 - accuracy: 0.7277 - recall: 0.7557 - val_loss: 0.5522 - val_accuracy: 0.7261 - val_recall: 0.6957\n",
      "Epoch 3/15\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.5212 - accuracy: 0.7226 - recall: 0.7453\n",
      "Epoch 3: val_loss improved from 0.55216 to 0.52197, saving model to melanoma_model.h5\n",
      "30/30 [==============================] - 158s 5s/step - loss: 0.5212 - accuracy: 0.7226 - recall: 0.7453 - val_loss: 0.5220 - val_accuracy: 0.7391 - val_recall: 0.7304\n",
      "Epoch 4/15\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.4737 - accuracy: 0.7723 - recall: 0.7826\n",
      "Epoch 4: val_loss improved from 0.52197 to 0.51727, saving model to melanoma_model.h5\n",
      "30/30 [==============================] - 80s 3s/step - loss: 0.4737 - accuracy: 0.7723 - recall: 0.7826 - val_loss: 0.5173 - val_accuracy: 0.7435 - val_recall: 0.8609\n",
      "Epoch 5/15\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.4702 - accuracy: 0.7754 - recall: 0.7888\n",
      "Epoch 5: val_loss improved from 0.51727 to 0.49271, saving model to melanoma_model.h5\n",
      "30/30 [==============================] - 76s 3s/step - loss: 0.4702 - accuracy: 0.7754 - recall: 0.7888 - val_loss: 0.4927 - val_accuracy: 0.7826 - val_recall: 0.8348\n",
      "Epoch 6/15\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.4238 - accuracy: 0.8106 - recall: 0.8282\n",
      "Epoch 6: val_loss did not improve from 0.49271\n",
      "30/30 [==============================] - 65s 2s/step - loss: 0.4238 - accuracy: 0.8106 - recall: 0.8282 - val_loss: 0.4937 - val_accuracy: 0.7565 - val_recall: 0.7130\n",
      "Epoch 7/15\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.4181 - accuracy: 0.8095 - recall: 0.8137\n",
      "Epoch 7: val_loss improved from 0.49271 to 0.47370, saving model to melanoma_model.h5\n",
      "30/30 [==============================] - 72s 2s/step - loss: 0.4181 - accuracy: 0.8095 - recall: 0.8137 - val_loss: 0.4737 - val_accuracy: 0.7826 - val_recall: 0.8261\n",
      "Epoch 8/15\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.3903 - accuracy: 0.8137 - recall: 0.8137\n",
      "Epoch 8: val_loss improved from 0.47370 to 0.46237, saving model to melanoma_model.h5\n",
      "30/30 [==============================] - 72s 2s/step - loss: 0.3903 - accuracy: 0.8137 - recall: 0.8137 - val_loss: 0.4624 - val_accuracy: 0.7957 - val_recall: 0.8087\n",
      "Epoch 9/15\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.3875 - accuracy: 0.8292 - recall: 0.8364\n",
      "Epoch 9: val_loss improved from 0.46237 to 0.45768, saving model to melanoma_model.h5\n",
      "30/30 [==============================] - 71s 2s/step - loss: 0.3875 - accuracy: 0.8292 - recall: 0.8364 - val_loss: 0.4577 - val_accuracy: 0.7870 - val_recall: 0.8522\n",
      "Epoch 10/15\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.3573 - accuracy: 0.8437 - recall: 0.8778\n",
      "Epoch 10: val_loss improved from 0.45768 to 0.45590, saving model to melanoma_model.h5\n",
      "30/30 [==============================] - 81s 3s/step - loss: 0.3573 - accuracy: 0.8437 - recall: 0.8778 - val_loss: 0.4559 - val_accuracy: 0.7870 - val_recall: 0.8435\n",
      "Epoch 11/15\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.3537 - accuracy: 0.8520 - recall: 0.8489\n",
      "Epoch 11: val_loss did not improve from 0.45590\n",
      "30/30 [==============================] - 64s 2s/step - loss: 0.3537 - accuracy: 0.8520 - recall: 0.8489 - val_loss: 0.4604 - val_accuracy: 0.8043 - val_recall: 0.9217\n",
      "Epoch 12/15\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.3471 - accuracy: 0.8489 - recall: 0.8758\n",
      "Epoch 12: val_loss improved from 0.45590 to 0.45196, saving model to melanoma_model.h5\n",
      "30/30 [==============================] - 74s 3s/step - loss: 0.3471 - accuracy: 0.8489 - recall: 0.8758 - val_loss: 0.4520 - val_accuracy: 0.7957 - val_recall: 0.8783\n",
      "Epoch 13/15\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.3205 - accuracy: 0.8613 - recall: 0.8634\n",
      "Epoch 13: val_loss improved from 0.45196 to 0.43500, saving model to melanoma_model.h5\n",
      "30/30 [==============================] - 72s 2s/step - loss: 0.3205 - accuracy: 0.8613 - recall: 0.8634 - val_loss: 0.4350 - val_accuracy: 0.8000 - val_recall: 0.8609\n",
      "Epoch 14/15\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.3133 - accuracy: 0.8737 - recall: 0.9068\n",
      "Epoch 14: val_loss improved from 0.43500 to 0.43480, saving model to melanoma_model.h5\n",
      "30/30 [==============================] - 73s 2s/step - loss: 0.3133 - accuracy: 0.8737 - recall: 0.9068 - val_loss: 0.4348 - val_accuracy: 0.7913 - val_recall: 0.8000\n",
      "Epoch 15/15\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.2916 - accuracy: 0.8913 - recall: 0.9193\n",
      "Epoch 15: val_loss did not improve from 0.43480\n",
      "30/30 [==============================] - 66s 2s/step - loss: 0.2916 - accuracy: 0.8913 - recall: 0.9193 - val_loss: 0.4402 - val_accuracy: 0.7913 - val_recall: 0.8522\n",
      "Model training completed successfully.\n"
     ]
    }
   ],
   "source": [
    "my_model = train_model('melanoma_model.h5',force_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dbbf2cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 8s 1s/step\n"
     ]
    }
   ],
   "source": [
    "probabilities = my_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6c08601e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_to_binary(pred):\n",
    "    if pred < 0.5:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "y_pred_CNN = [pred_to_binary(x) for x in probabilities]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "036f2f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7717\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print('Accuracy:', np.round(metrics.accuracy_score(y_test, y_pred_CNN),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "27ee8743",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing predictions...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m test_images_id \u001b[38;5;241m=\u001b[39m test_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage_name\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mComputing predictions...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m probabilities \u001b[38;5;241m=\u001b[39m \u001b[43mmy_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras/engine/training.py:2253\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   2251\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39msteps():\n\u001b[1;32m   2252\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_predict_batch_begin(step)\n\u001b[0;32m-> 2253\u001b[0m     tmp_batch_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2254\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   2255\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:954\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    951\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    952\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    953\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 954\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateful_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[1;32m    956\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    957\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2494\u001b[0m   (graph_function,\n\u001b[1;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1865\u001b[0m     args,\n\u001b[1;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1867\u001b[0m     executing_eagerly)\n\u001b[1;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_images_id = test_df['image_name']\n",
    "print('Computing predictions...')\n",
    "probabilities = my_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3040d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame\n",
    "results_df = pd.DataFrame({\n",
    "    'image_name': test_images_id,\n",
    "    'target': probabilities.flatten()\n",
    "})\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a72c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = test_df[['image_name','target']]\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0405bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "del sub['target']\n",
    "sub = sub.merge(results_df, on='image_name')\n",
    "sub.to_csv('submission_image.csv', index=False)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a471b5f",
   "metadata": {},
   "source": [
    "## Training using Tabular Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669e8511",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df[['sex_male', 'anatom_head/neck',\n",
    "       'anatom_lower extremity', 'anatom_oral/genital', 'anatom_palms/soles',\n",
    "       'anatom_torso', 'anatom_upper extremity','age_approx']]\n",
    "y_train = train_df['target']\n",
    "X_val = val_df[['sex_male', 'anatom_head/neck',\n",
    "       'anatom_lower extremity', 'anatom_oral/genital', 'anatom_palms/soles',\n",
    "       'anatom_torso', 'anatom_upper extremity','age_approx']]\n",
    "y_val = val_df['target']\n",
    "X_test = test_df[['sex_male', 'anatom_head/neck',\n",
    "       'anatom_lower extremity', 'anatom_oral/genital', 'anatom_palms/soles',\n",
    "       'anatom_torso', 'anatom_upper extremity','age_approx']]\n",
    "y_test = test_df['target'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0de078d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "classifier_xgb = xgb.XGBClassifier(n_estimators = 300)\n",
    "classifier_xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474f7b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_xgb = classifier_xgb.predict_proba(X_test)\n",
    "y_pred_xgb = y_pred_xgb[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f1eb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame\n",
    "results_df = pd.DataFrame({\n",
    "    'image_name': test_images_id,\n",
    "    'target': y_pred_xgb\n",
    "})\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c643fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = test_df[['image_name','target']]\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc8b3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "del sub['target']\n",
    "sub = sub.merge(results_df, on='image_name')\n",
    "sub.to_csv('submission_tabular.csv', index=False)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ed77a7",
   "metadata": {},
   "source": [
    "## Use Both Image and Tabular Data\n",
    "\n",
    "Kaggle's Melanoma Classification competition provides both image data and tabular data about each sample. Our task is to use both types of data to predict the probability that a sample is malignant. How can we build a model that uses both images and tabular data?\n",
    "\n",
    "Three ideas come to mind.\n",
    "\n",
    "1. Build a CNN image model and find a way to input the tabular data into the CNN image model\n",
    "2. Build a Tabular data model and find a way to extract image embeddings and input into the Tabular data model\n",
    "3. Build 2 separate models and ensemble\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1ebefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_sub = pd.read_csv('./submission_image.csv')\n",
    "tabular_sub = pd.read_csv('./submission_tabular.csv')\n",
    "image_sub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5d8470",
   "metadata": {},
   "source": [
    "We are ensembling based on weighted average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401e1b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = image_sub.copy()\n",
    "sub.target = 0.9 * image_sub.target.values + 0.1 * tabular_sub.target.values\n",
    "sub.to_csv('submission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
